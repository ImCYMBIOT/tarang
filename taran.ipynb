{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Flatten, Dropout, Activation\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load and preprocess search history data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_data = pd.read_json('search_history.json')\n",
    "search_data['searchTime'] = pd.to_datetime(search_data['searchTime'])\n",
    "search_data['hour_of_day'] = search_data['searchTime'].dt.hour\n",
    "search_data['day_of_week'] = search_data['searchTime'].dt.dayofweek\n",
    "search_data['query_length'] = search_data['searchQuery'].apply(lambda x: len(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess streaming history data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_data = pd.read_json('streaming_history.json')\n",
    "streaming_data['endTime'] = pd.to_datetime(streaming_data['endTime'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_data = pd.read_json('user_demographics.json')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess user demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_data['birthdate'] = pd.to_datetime(demographics_data['birthdate'])\n",
    "demographics_data['age'] = (pd.to_datetime('today') - demographics_data['birthdate']).astype('<m8[Y]')\n",
    "demographics_data['gender'] = LabelEncoder().fit_transform(demographics_data['gender'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = pd.merge(search_data, streaming_data, how='outer', on='username')\n",
    "merged_data = pd.merge(merged_data, demographics_data, how='inner', on='username')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['platform'] = LabelEncoder().fit_transform(merged_data['platform'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "merged_data[['msPlayed']] = scaler.fit_transform(merged_data[['msPlayed']])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(merged_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare inputs for LSTM architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_inputs = train_data[['hour_of_day', 'day_of_week', 'query_length']]\n",
    "search_inputs = np.asarray(search_inputs)\n",
    "search_inputs = np.expand_dims(search_inputs, axis=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare inputs for collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_inputs = train_data[['age', 'gender', 'country']]\n",
    "user_inputs = np.asarray(user_inputs)\n",
    "user_inputs = to_categorical(user_inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare targets for collaborative filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_inputs = train_data[['msPlayed']]\n",
    "target_inputs = np.asarray(target_inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM architecture for search history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_input = Input(shape=(3, 1))\n",
    "lstm_output = LSTM(64)(lstm_input)\n",
    "lstm_output = Dense(32, activation='relu')(lstm_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Autoencoder architecture for collaborative filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = Input(shape=(user_inputs.shape[1],))\n",
    "user_embedding = Dense(64, activation='relu')(user_input)\n",
    "\n",
    "target_input = Input(shape=(target_inputs.shape[1],))\n",
    "target_embedding = Dense(64, activation='relu')(target_input)\n",
    "\n",
    "merged_layer = Concatenate()([user_embedding, target_embedding])\n",
    "encoded = Dense(32, activation='relu', activity_regularizer=regularizers.l1(10e-5))(merged_layer)\n",
    "decoded = Dense(64, activation='relu')(encoded)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(inputs=[user_input, target_input], outputs=decoded)\n",
    "autoencoder.compile(optimizer=Adam(lr=0.001), loss=MeanSquaredError())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit([user_inputs, target_inputs], target_inputs, epochs=10, batch_size=32, validation_split=0.2, callbacks=[EarlyStopping(patience=3)])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract embeddings from the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = Model(inputs=user_input, outputs=user_embedding)\n",
    "user_embeddings = embedding_model.predict(user_inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
